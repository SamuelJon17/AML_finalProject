{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43dee206",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering (NCF)\n",
    "References:\n",
    "* https://github.com/microsoft/recommenders \n",
    "* https://towardsdatascience.com/neural-collaborative-filtering-96cef1009401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8261cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.models.ncf.ncf_singlenode import NCF\n",
    "from recommenders.models.ncf.dataset import Dataset as NCFDataset\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.utils.notebook_utils import is_jupyter\n",
    "from recommenders.datasets.python_splitters import python_chrono_split\n",
    "from recommenders.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k, \n",
    "                                                     recall_at_k, get_top_k_items)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing as pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6022eb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries = 31519\n",
      "Total number of unique users = 398\n",
      "Total number of unique books = 24542\n",
      "Train Size  :  25215\n",
      "Test Size :  6304\n",
      "Number of Unique Users :  398\n",
      "Number of unique Books :  20177\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"source/supporting/goodreads_interactions.csv\")\n",
    "\n",
    "# TESTING MODE\n",
    "data = data.iloc[0:500000]\n",
    "#data = data.sample(n=10000000)\n",
    "\n",
    "## Focus on read and reviewed only i.e., remove is_reviewed == 0 and rating == 0\n",
    "data = data[(data['is_reviewed']==1)&(data['rating']!=0)]\n",
    "\n",
    "## Focus on users that have more than 10 book ratings\n",
    "ratings_per_user = data[(data['is_reviewed']==1)&(data['rating']!=0)].groupby('user_id').size().reset_index(name='number_of_ratings_per_user')\n",
    "data = data[data.user_id.isin(set(ratings_per_user[ratings_per_user['number_of_ratings_per_user']>=10]['user_id']))]\n",
    "\n",
    "## Focus on ratings >= 3  \n",
    "## NOTE: in the future could use no rating - rating 2 as negative data? \n",
    "data = data[data.rating>=3]\n",
    "\n",
    "## Remove is_reviewed and is_read\n",
    "data = data[['user_id','book_id','rating']]\n",
    "\n",
    "# Basic statistics about the dataset\n",
    "print(f\"Total number of entries = {len(data)}\")\n",
    "print(f\"Total number of unique users = {len(set(data['user_id']))}\")\n",
    "print(f\"Total number of unique books = {len(set(data['book_id']))}\")\n",
    "\n",
    "\n",
    "# Perform a 80/20 train-test split on the interactions in the dataset\n",
    "train, test = train_test_split(data.values, test_size=0.2, random_state=17)\n",
    "train_df = pd.DataFrame(train, columns=data.columns)\n",
    "test_df = pd.DataFrame(test, columns=data.columns)\n",
    "print(\"Train Size  : \", len(train_df))\n",
    "print(\"Test Size : \", len (test_df))\n",
    "\n",
    "## Relabel IDs train set for both user and book ids\n",
    "le_user = pp.LabelEncoder()\n",
    "le_item = pp.LabelEncoder()\n",
    "train_df['user_id_idx'] = le_user.fit_transform(train_df['user_id'].values)\n",
    "train_df['book_id_idx'] = le_item.fit_transform(train_df['book_id'].values)\n",
    "\n",
    "## Test items that are only present in the train set (i.e., user and book id that are in train set)\n",
    "test_df = test_df[(test_df['user_id'].isin(train_df['user_id'].unique())) & (test_df['book_id'].isin(train_df['book_id'].unique()))]\n",
    "\n",
    "## Relabel IDs for test set for both user and book ids\n",
    "test_df['user_id_idx'] = le_user.transform(test_df['user_id'].values)\n",
    "test_df['book_id_idx'] = le_item.transform(test_df['book_id'].values)\n",
    "\n",
    "## Preparing for Micorosft's Input -- requires timestamp even though timestamp isn't used\n",
    "train_df = train_df[['user_id_idx','book_id_idx','rating']]\n",
    "train_df.rename(columns={\"user_id_idx\":\"userID\", \"book_id_idx\":\"itemID\"}, inplace =True)\n",
    "train_df['timestamp'] = 0\n",
    "\n",
    "test_df = test_df[['user_id_idx','book_id_idx','rating']]\n",
    "test_df.rename(columns={\"user_id_idx\":\"userID\", \"book_id_idx\":\"itemID\"}, inplace =True)\n",
    "test_df['timestamp'] = 0\n",
    "\n",
    "## Print number of unique users and books after filter\n",
    "n_users = train_df['userID'].nunique()\n",
    "n_items = train_df['itemID'].nunique()\n",
    "print(\"Number of Unique Users : \", n_users)\n",
    "print(\"Number of unique Books : \", n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d1537f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETUP\n",
    "args = {\n",
    "    'n_layers' : 16,\n",
    "    'n_factors' : 4,\n",
    "    'epochs' : 50,\n",
    "    'lr': 0.005,\n",
    "    'batch_size' : 1024,\n",
    "    'K':20,\n",
    "    'seed':17\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e775449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendTopKAll():\n",
    "    with Timer() as test_time:\n",
    "        users, items, preds = [], [], []\n",
    "        item = list(train_df.itemID.unique())\n",
    "        for user in train_df.userID.unique():\n",
    "            user = [user] * len(item) \n",
    "            users.extend(user)\n",
    "            items.extend(item)\n",
    "            preds.extend(list(model.predict(user, item, is_list=True)))\n",
    "        all_predictions = pd.DataFrame(data={\"userID\": users, \"itemID\":items, \"prediction\":preds})\n",
    "        merged = pd.merge(train_df, all_predictions, on=[\"userID\", \"itemID\"], how=\"outer\")\n",
    "        all_predictions = merged[merged.rating.isnull()].drop(['rating','timestamp'], axis=1)\n",
    "    print(\"Took {} seconds for prediction.\".format(test_time))\n",
    "    return all_predictions\n",
    "\n",
    "def recommendTopK(predictions, train_df, test_df, userID=0, K=20):\n",
    "    predictions = predictions[predictions['userID']==userID]\n",
    "    predictions = predictions.sort_values('prediction', ascending=False)\n",
    "    predictions = predictions.iloc[:K].reset_index(drop=True)\n",
    "    interaction_train = train_df[train_df[\"userID\"]==userID].groupby('userID')['itemID'].apply(list).iloc[0]\n",
    "    interaction_test = test_df[test_df[\"userID\"]==userID].groupby('userID')['itemID'].apply(list).iloc[0]\n",
    "    predictions['inTrain'] = predictions.apply(lambda x: True if x.itemID in interaction_train else False, axis=1)\n",
    "    predictions['inTest'] = predictions.apply(lambda x: True if x.itemID in interaction_test else False, axis=1)\n",
    "    return predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ff3a96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.models.ncf.dataset:Indexing ./source/supporting/NGCFtrain.csv ...\n",
      "INFO:recommenders.models.ncf.dataset:Indexing ./source/supporting/NGCFtest.csv ...\n",
      "INFO:recommenders.models.ncf.dataset:Indexing ./source/supporting/NGCFtest_full.csv ...\n"
     ]
    }
   ],
   "source": [
    "train_file = \"./source/supporting/NGCFtrain.csv\"\n",
    "test_file = \"./source/supporting/NGCFtest.csv\"\n",
    "train_df.sort_values(\"userID\").to_csv(train_file, index=False)\n",
    "test_df.sort_values(\"userID\").to_csv(test_file, index=False)\n",
    "data_ = NCFDataset(train_file=train_file, test_file=test_file, seed=args['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2cfb628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samueljon/opt/anaconda3/envs/cs5525/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model = NCF (\n",
    "    n_users=data_.n_users, \n",
    "    n_items=data_.n_items,\n",
    "    model_type=\"NeuMF\",\n",
    "    n_factors=args['n_factors'],\n",
    "    layer_sizes=[args['n_layers']],\n",
    "    n_epochs=args['epochs'],\n",
    "    batch_size=args['batch_size'],\n",
    "    learning_rate=args['lr'],\n",
    "    verbose=10,\n",
    "    seed=args['seed']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1069c0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 10 [2.78s]: train_loss = 0.213595 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 20 [2.79s]: train_loss = 0.155225 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 30 [2.97s]: train_loss = 0.125712 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 40 [3.01s]: train_loss = 0.112959 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 50 [3.49s]: train_loss = 0.103548 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 161.0640 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit(data_)\n",
    "print(\"Took {} seconds for training.\".format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4e8cfe0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 17.0902 seconds for prediction.\n",
      "MAP:\t0.010273\n",
      "NDCG:\t0.019462\n",
      "Precision@K:\t0.005714\n",
      "Recall@K:\t0.024344\n"
     ]
    }
   ],
   "source": [
    "all_predictions = recommendTopKAll()\n",
    "eval_map = map_at_k(test_df, all_predictions, col_prediction='prediction', k=args['K'])\n",
    "eval_ndcg = ndcg_at_k(test_df, all_predictions, col_prediction='prediction', k=args['K'])\n",
    "eval_precision = precision_at_k(test_df, all_predictions, col_prediction='prediction', k=args['K'])\n",
    "eval_recall = recall_at_k(test_df, all_predictions, col_prediction='prediction', k=args['K'])\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "005c3ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "      <th>inTrain</th>\n",
       "      <th>inTest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1275</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3071</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3323</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2844</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2858</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>6439</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1343</td>\n",
       "      <td>0.999835</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>2530</td>\n",
       "      <td>0.999213</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>15130</td>\n",
       "      <td>0.998712</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>3239</td>\n",
       "      <td>0.998532</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2220</td>\n",
       "      <td>0.997701</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>3312</td>\n",
       "      <td>0.997371</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>2888</td>\n",
       "      <td>0.997198</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>3399</td>\n",
       "      <td>0.993831</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>4090</td>\n",
       "      <td>0.992791</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>1360</td>\n",
       "      <td>0.991973</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>1133</td>\n",
       "      <td>0.990922</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>802</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>1612</td>\n",
       "      <td>0.987822</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userID  itemID  prediction  inTrain  inTest\n",
       "0        3    1275    0.999999    False    True\n",
       "1        3    3071    0.999989    False   False\n",
       "2        3    3323    0.999989    False   False\n",
       "3        3    2844    0.999985    False   False\n",
       "4        3    2858    0.999976    False   False\n",
       "5        3    6439    0.999887    False   False\n",
       "6        3    1343    0.999835    False   False\n",
       "7        3    1549    0.999686    False   False\n",
       "8        3    2530    0.999213    False   False\n",
       "9        3   15130    0.998712    False   False\n",
       "10       3    3239    0.998532    False   False\n",
       "11       3    2220    0.997701    False   False\n",
       "12       3    3312    0.997371    False    True\n",
       "13       3    2888    0.997198    False   False\n",
       "14       3    3399    0.993831    False   False\n",
       "15       3    4090    0.992791    False   False\n",
       "16       3    1360    0.991973    False   False\n",
       "17       3    1133    0.990922    False   False\n",
       "18       3     802    0.988050    False   False\n",
       "19       3    1612    0.987822    False   False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendTopK(all_predictions,train_df, test_df, userID=3, K=args['K'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d11ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1273c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5525",
   "language": "python",
   "name": "cs5525"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
